Project RISCII Software Design Plan
by John Eslinger
================================================================================
Table of Contents:
	-> Overview and Additional Details
	-> Creating the Abstract Syntax Tree
	-> Checking for Correctness
	-> Translating the Code
================================================================================
Overview and Additional Details:
	Compiler Inputs and Outputs:
		-> Compiler requires an input .c file to read/translate
		-> Output is reliant on result of compiling
			(Produces a .hex file only if compilation is successful)
			(Prints warnings and errors to stdout)
			(Executable returns 0 if compilation is successful)
		-> Additional flags can be added to change behavior
			(-h: help flag- prints out command usage to stdout, then exits)
			(-v: prints extra info to stdout while running)
			(-s: creates assembly file if hex file is made)
			(-O1: performs "win-win" optimizations while compiling)
			(-Werror: treats warnings as errors)
	
	High Level Architecture:
		-> Compiler is broken into 7 stages
			(Scanning and Parsing stages format file's code for other stages)
			(Semantic and Type Checking stages ensure code is translatable)
			(Optimizing, Translation, and Assembly stages generate machine code)
		-> Various data structures are passed between the stages)
			(The Abstract Syntax Tree, or AST, is the primary shared structure)
			(Additional data structures include the Token List and Symbols)
		-> High level common code handles user IO operations
			(File operations- creating, reading, writing, deleting files)
			(Stdout operations- warnings, errors, verbose output)
			(Returning- stages should not call exit() directly)

================================================================================
Creating the Abstract Syntax Tree:
	Scanning Stage:
		-> Tokenizes original file
			(Original file can be viewed as list of characters)
			(Characters can be grouped into "words" known as tokens)
			(Tokenizing allows for parsing while also performing syntax checks)
		-> Recognized tokens:
			Operators: & | ^ ~ << >> + - = > < <= >= == != ! { } ( ) ; ,
			Keywords: if while return char int unsigned
			Identifier: foobar (Regex = " [_a-zA-Z_][_a-zA-Z0-9_]* ")
			Char Literal: '\n' (Regex = " '([^\n\t\\']|\[nt\\'])' ")
			Int Literal: 42 (Regex = " [-]?[0-9]+ ")
			Hex Literal: 0xaB21 (Regex = " 0x[a-fA-F0-9]+ ")
			Comment: //... (Regex = " //[^\n]* ") (Note: Don't save comments)
		-> Data Structure- Scanning Table
			(Each token has a state machine defining valid character sequences)
			(State machines can be combined into one for total token detection)
			(A 2D-array allows for easy tracking of state and detected token)
				- Bounds defined by non-terminal states and valid characters
				- Each cell contains the new state for state/character pair
				- Memory intensive, but eliminates awkward transition logic
		-> Scanner Stage Pseudocode
			state, buffer, lineNum = start, empty, 1;
			for each char in file:
				if (peekChar() == badChar): badCharERR(peekChar(), lineNum);
				state = scanTable[state][peekChar()];
				if (state == error): badTknERR(peekChar(), buffer, lineNum);
				else if (state == terminal):
					if (lastCharInTkn): buffer += popChar(); // token dependent
					enqueueToken(state, buffer, lineNum); // To token's builder
					state, buffer = start, empty;
				else:
					char = popChar();
					if (char == \n): lineNum++;
					if (state != start): buffer += char;
		-> Notable Details
			(Visible ASCII chars, "\n", "\t", and EOF are valid- ignore "\r")
			(Think carefully about states- could use enum to "group" key ones)
			(A separate script may be desired to generate the scanning table)
			(Be aware of whitespaces/line counting- may rely on manual testing)
	
	Parsing Stage:
		-> Parses the token list into an Abstract Syntax Tree (AST)
			(Scanning creates an ordered list of tokens)
			(Tokens can be parsed into an AST for future compiler steps)
			(Parsing performs grammar checks and filters out unneeded tokens)
		-> Nodes used to build the AST:
			Raw Data: IDNode, LITNode
			Groups/Interfaces: declNode, stmtNode, expNode
			Globals: prgmNode, varDeclNode, funcDefNode
			Statements: assignNode, ifNode, whileNode, retNode, callNode
			Operators: <op>Node (one for each operator except "=" and "()")
		-> Data Structure- Parsing Table
			(Production rules can define grammar/building rules for language)
			(Nonterminal tokens can be defined as combinations of tokens)
			(A 2D-array allows for predictive parsing of the rules/tokens)
				- Bounds defined by nonterminal tokens vs. terminal tokens
				- Each cell specifies tokens to predict and/or actions to take
				- Memory intensive, but simplifies process heavily
		-> Parsing Stage Pseudocode			
			parseStk.push(EOF, prgmTkn);
			buildStk.empty();
			tkn = nextToken();
			while (parseStk != empty):
				obj = parseStk.pop();
				if (obj == nonTerminal):
					if (parseTable.empty(obj,tkn)): unexpectedTknERR(tkn);
					else: parseStk.pushList(parseTable[obj][tkn];
				else if (obj == terminal):
					if (obj != tkn): expectedTknERR(obj, tkn);
					else: tkn = nextToken();
				else: buildStk.runBuildActions(obj); // obj == AST build action
		-> Notable Details
			(EOF counts as a terminal token, even if no direct token exists)
			(A separate script may be desired to generate the parsing table)
			(Be very cautious when designing the parsing table)
				- Cells can hold a list of tokens, a function, or an error
				- Ensure precedence and associativity rules are followed
				- Be careful about tokens parsing through multiple rules
				
================================================================================
Checking for Correctness:
	Semantic Checking Stage:
		-> Semantically checks/evaluates the program's identifiers (i.e. IDs)
			(Ensures ID declarations are unique per scope)
			(Checks IDs used have been declared in an accessible scope)
			(Creates list of symbols for use in later stages)
		-> Symbols
			(Symbols hold info for each unique ID)
				- ID type/signature for type checking
				- Constant value for copy propagation optimizing
				- Memory location for translation
			(Declarations/calls linked to symbol for common information)
			(Symbols last even after symbol table is discarded)
		-> Data Structure- Symbol Table Operations:
			addScope(): Pushes a new local scope (similar to a stack push)
			popScope(): Pops local scope (similar to a stack pop)
			getLocal(name): Searches local scope for ID by its name
			getGlobal(name): Searches all scopes for ID by its name
				- Returns the lowest scope symbol if multiple exist
			addSym(symbol): Adds symbol to local scope
		-> Notable Actions (by AST Node)
			(DeclNodes add symbols, checking for multiply declared IDs)
			(IDNodes link to symbols, checking for undeclared IDs)
			(PrgmNode checks if "int main()" symbol was created)
			(Warnings for "uninitialized" and "unused" IDs)
				- AssignNode flags initialization, IDNode checks use
				- IDNode flags use, prgmNode checks final count
		-> Additional Notes
			(Some nodes (e.g. IDNodes) will implicitly have symbol pointers)
			(Symbol table is dicarded after stage in favor for linked symbols)
			(Line-number-ordered warnings may require a buffer)
	
	Type Checking Stage:
		-> Performs rest of pertinent checks- namely ID type checks
			(Ensures IDs are used correctly with respect to their type)
			(Determines if expressions will combine values without error)
			(Checks functions are properly formatted and called)
		-> Types and Conversions
			(Types: char, unsigned char, int, unsigned int, literal)
			(Some types can be upcasted without warning)
				- unsigned char -> int, unsigned int
				- char -> int
			(Literals can be "upcasted" depending on their value)
				- char			{-128 <= value <= 127}
				- unsigned char	{0 <= value <= 255}
				- int			{-32768 <= value <= 32767}
				- unsigned int	{0 <= value <= 65535}
		-> Checked Errors and Warnings
			(Errors related to mis-using name type or signature)
				- Using variable name as function name
				- Using function name as variable name
				- Wrong number or arguments in function call
			(Warnings related to bad type conversions or function formatting)
				- Assignment, operator, or argument type couldn't resolve well
				- Literal too large to fit into int/unsigned int
				- No return statement detected
				- Statements after return statement
				- Conditional of if/while loop is clearly constant
		-> General Approach (based on AST Nodes)
			(Errors can be checked at IDNode and callNodes via linked symbol)
			(Type warnings are checked by passing by accumulated type)
				- Overall expression type evaluated from names/literals up
				- Mismatches require conversion algorithm to determine type
				- Algorithm must also determine if a warning is called for
			(Function formatting warnings determined at scope boundaries)
				- Constant conditionals found at if/while nodes
				- Returns found at "always-run" scopes, once per function
				- Statements found post-return in any scope, per scope
		-> Additional Notes
			(Some type conversions have a determined answer, like assignments)
			(Symbols may be used to store type and warning flag metadata)
			(Line-number-ordered warnings may require a buffer)

================================================================================
Translating the Code:
	Optimizing Stage:
		-> Stage that (optionally) adds optimizing details to the AST/symbols
			(Stage always runs, but some optimizations require "-O1" flag)
			(Scans AST/symbols looking for optimizable code)
				- pruning of unused variables/functions/statements
				- precomputation of expressions/conditions/functions
			(Translator uses resulting details to create optimized program)
		-> Optimizer Details (Stored in AST/symbols)
			(Symbols store flag to verify at least one read/use)
			(Unreachable stmtNodes are deleted from the AST)
			(ExpNodes store/are replaced by precomputed constants if able)
			(Function symbol stores constant return value if available)
		-> Data Structure- Constant List (Constant Propagation Strategy)
			(Links symbols and constant values)
			(Allows replacing variable reads with constants and precomputing)
			(Constant list used in different scenarios)
				- Modified by AssignNodes and exiting blocks
				- Read by IDNodes to get "precomputed" constant
				- Passed between nodes to share (or not share) constants
		-> Notable Optimization Cases
			(Functions become constants if all returns use same constant)
			(Post-return statement lines, in the same scope, are unreachable)
			(If/While blocks have special propagation/pruning rules)
				- constant list must be modified pre/post block
				- "while" condtion has "first" and "next" constant evaluations
				- constant conditions can prune jump/condition/block code
		-> Additional Details
			(Global variables cannot be optimized due to function calls)
			(Constant lists are passed down, precomputed constants are returned)
			("Loop invariants" can enhance "while" block analysis)
				- invariant = {block variables read} - {block variables written}
				- invariants in constant list carry to block's constant list
	
	Translation Stage:
		-> Translates AST/symbols into assembly code
			(Stage realizes majority of addresses and computations)
				- Order of operations
				- RAM addresses/offsets
				- Load/Store overhead
			(Labels used to export ROM address realization to assembler)
			(Creates file for assembler- file persists if "-s" flag given)
		-> Register File and Stack Layouts
			(Register File has 8 registers across 5 sections)
				- Stack pointer: Top of the stack
				- Frame pointer: Bottom of current stack frame
				- Accumulator: Result of operation or call
				- Address pointer: Backup pointer for jumps and RAM accesses
				- Load registers: Four registers for loading operands
			(Stack has 5 sections between stack and frame pointer)
				- Return address: 2-byte address to jump to after frame
				- Control link: 2-byte value of previous frame pointer
				- Local Variables: n-bytes of data used by frame
				- Caller Saves: Saved load registers, only when calling
				- Arguments: Arguments for next frame, only when calling
		-> Important "Levelled" Operations
			(Loads/stores vary due to limitations with base+offset instructions)
				- value in register file: no cost (loads only) (+0 overhead)
				- value near pointer: simple load/store (+1 overhead)
				- value just out of reach: addi/subi + load/store (+2 overheads)
				- else:  1-2 lbi + add/sub + load/store (+3-4 overhead)
			(Constant operands may use "immediate" field in instruction)
			(Jumps may either be "jal/brc" or "lbi + lbi + jlr" macro)
		-> Notable Translation Actions
			(ExpNodes evaluate children, generate loads, and generate operation)
			(Special care must be made when handling accumulated values)
				- An expression may have 2+ accumulated values at once
				- One must be temporarily saved on the stack
				- Use unique IDs per value per expression to track them
			(Function start/end requires body to be evaluated for frame size)
		-> Additional Details
			(Function's out-of-order translation requires buffering the output)
			(All expressions should store result in accumulator for consistency)
				- consider "single ID/literal" expression
			("BIOS" should be generated to jump to main and store result to 0x0)
			(Can use "canaries" to provide weak stack overflow detection)
				- stack limit set with specific value (ie a "canary")
				- if stack grows past it, value will likely be changed
				- function (call) can check for change and act accordingly
	
	Assembly Stage:
		-> Translates assembly code into binary machine code
			(Assembly based on instructions specified in ISA.txt)
			(Supports jumping to labels by using a built-in macro)
			(Translation occurs in two phases)
				- Phase 1 parses instructions, macros, and label addresses
				- Phase 2 converts instruction and macros into hex machine code
		-> Assembly Language Specifications
			(Each line is a spacer, label, instruction, or macro)
			(Comments can be appended to any type of line)
			("Tokens" of the assembly language)
				- comment: ";[any text after semicolon]\n"
				- labelled address: "<identifier>:"
				- macro: "_to <identifier>"
				- instruction opcode: (3 capital letters- see ISA.txt)
				- flags: "a" for SHR, "s" for LBI, "nzp" combo for BRC
				- register: "r[0-7]"
				- immediate: (decimal number- limits based on instruction)
		-> Data Structures- Instruction Buffer, Address Log, and Entries
			(Entry used to record pertinent info on parsed instruction)
				- entry type defines instruction type (or if a macro)
				- data type summarizes operand types (bit fields for 4 operands)
				- vector (length 1-4) defines operand number values
			(Instruction buffer holds ordered entries for future parsing)
			(Address log stores pairs of labels/addresses)
		-> Function Pieces- Tokenizers, Converters, and Handlers
			(Two tokenizers- first token type and operand types/values)
			(Converters focus on checking values are valid and translating)
				- Functions take bit field values, output combined hex value
				- About 7 unique bit field patterns exist in ISA
			(Handler functions exist for each instruction type and macro)
				- Array of handlers allow entry type to quickly find handler
				- Data type allows handler to quickly choose converter
		-> Additional Details
			(Consider scan table vs. regexes for tokenizer implementation)
			(Built-in macro always translates to {LBI,LBI,JLR} instructions)
			(Consider how assembler may be independet of the compiler)
				- Assembler can act like independent "mini-compiler"
				- Compiler uses assembler to link C code and machine code

================================================================================